{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Задание 1: Выбор датасета\n",
    "# Для примера используем датасет отзывов на фильмы IMDb.\n",
    "\n",
    "# Загрузка датасета IMDb Movie Reviews\n",
    "# Датасет должен быть предварительно загружен в вашу рабочую директорию.\n",
    "imdb_dataset = pd.read_csv('IMDB Dataset.csv', encoding='utf-8')\n",
    "\n",
    "# Задание 2: Разметка на основе правил\n",
    "# Функция разметки текстов на основе содержания определенных слов\n",
    "\n",
    "def rule_based_labeling(text):\n",
    "\"\"\"\n",
    "Функция для автоматической разметки текста.\n",
    "Если в тексте встречаются слова 'great' или 'excellent', метка становится 'positive'.\n",
    "В противном случае метка 'negative'.\n",
    "\"\"\"\n",
    "if \"great\" in text or \"excellent\" in text:\n",
    "return \"positive\"\n",
    "else:\n",
    "return \"negative\"\n",
    "\n",
    "# Применяем разметку на основе правил к случайному подмножеству датасета\n",
    "labeled_data = imdb_dataset.sample(frac=0.2) # Взятие 20% от всего датасета\n",
    "labeled_data['label'] = labeled_data['review'].apply(rule_based_labeling) # Предполагаем, что столбец с отзывами называется 'review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Задание 1: Выбор датасета\n",
    "# Для примера используем датасет отзывов на фильмы IMDb.\n",
    "\n",
    "# Загрузка датасета IMDb Movie Reviews\n",
    "# Датасет должен быть предварительно загружен в вашу рабочую директорию.\n",
    "imdb_dataset = pd.read_csv('D:/git_education/seminar_Data_collection_and_markup/seminar_9/IMDB Dataset.csv', encoding='utf-8')\n",
    "\n",
    "# Задание 2: Разметка на основе правил\n",
    "# Функция разметки текстов на основе содержания определенных слов\n",
    "\n",
    "def rule_based_labeling(text):\n",
    "  \"\"\"\n",
    "  Функция для автоматической разметки текста.\n",
    "  Если в тексте встречаются слова 'great' или 'excellent', метка становится 'positive'.\n",
    "  В противном случае метка 'negative'.\n",
    "  \"\"\"\n",
    "  if \"great\" in text or \"excellent\" in text:\n",
    "    return \"positive\"\n",
    "  else:\n",
    "    return \"negative\"\n",
    "\n",
    "# Применяем разметку на основе правил к случайному подмножеству датасета\n",
    "labeled_data = imdb_dataset.sample(frac=0.2) # Взятие 20% от всего датасета\n",
    "labeled_data['label'] = labeled_data['review'].apply(rule_based_labeling) # Предполагаем, что столбец с отзывами называется 'review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data.to_csv('task_2_sem_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перезагрузка данных и применение функции анализа настроений, адаптированной под английский язык\n",
    "\n",
    "# Повторная загрузка данных из файла\n",
    "tweets_data = pd.read_csv(\"tweets.csv\")\n",
    "\n",
    "# Адаптация функции анализа настроений под английский язык\n",
    "def sentiment_analysis(text):\n",
    "    \"\"\"\n",
    "    Функция для определения настроения текста на английском языке.\n",
    "    Возвращает 'positive' для текстов с положительными ключевыми словами,\n",
    "    'negative' для текстов с негативными ключевыми словами,\n",
    "    и 'neutral', если ключевые слова не найдены.\n",
    "    \"\"\"\n",
    "    positive_keywords = ['good', 'great', 'excellent', 'positive', 'joy', 'happy']\n",
    "    negative_keywords = ['bad', 'terrible', 'disappointed', 'negative', 'problem', 'sad']\n",
    "\n",
    "    text = text.lower() # Приведение текста к нижнему регистру для упрощения сравнения\n",
    "    if any(keyword in text for keyword in positive_keywords):\n",
    "      return 'positive'\n",
    "    elif any(keyword in text for keyword in negative_keywords):\n",
    "      return 'negative'\n",
    "    else:\n",
    "      return 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предполагаем, что ручная разметка уже выполнена и результаты сохранены в файле\n",
    "manually_labeled_data = pd.read_csv(\"anually_labeled.csv\")\n",
    "\n",
    "# Объединение автоматически размеченных данных с ручной разметкой\n",
    "combined_data = pd.concat([tweets_data, manually_labeled_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['sentiment'].fillna('neutral', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split — это функция из библиотеки scikit-learn,\n",
    "# которая используется для разделения массивов или матриц на\n",
    "# случайные подвыборки обучающих и тестовых данных.\n",
    "# Основная цель этой функции — разделить данные на две части: одну для обучения модели, а другую для проверки её эффективности. Это помогает оценить, как модель будет работать на новых, ранее не виденных данных, тем самым проверяя её способность к обобщению.\n",
    "\n",
    "# Подготовка данных для обучения\n",
    "X = combined_data['text'] # Используем текст твитов\n",
    "y = combined_data['sentiment'] # Используем метки настроения\n",
    "\n",
    "# Векторизация текста\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Задание 6: Оценка модели\n",
    "# Прогнозирование меток для тестовых данных\n",
    "y_test_predicted = model.predict(X_test)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_test_predicted)\n",
    "print(f'Точность модели: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
